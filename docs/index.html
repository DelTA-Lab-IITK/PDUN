
<html class="gr__filebox_ece_vt_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous">
	<style>
	body {
		background: white;
		color: #222222;
		padding: 0;
		margin: 0;
		font-family: "Helvetica Neue", "Helvetica", Helvetica, Arial, sans-serif;
		font-weight: normal;
		font-style: normal;
		line-height: 1.4;
   }
	a:link {
		text-decoration: none;
	}
	a:visited {
		text-decoration: none;
	}
	a:hover {
		text-decoration: underline;
	}
	a:active {
		text-decoration: underline;
	}
	p{
		font-size:1.2em;
	}
	img {
		width:100%;
		max-width: 300px;
	}
	.rcorner{
		border-radius: 25px;
		border: 2px solid #8AC007;
		padding: 20px;
	}
	div{
		max-width:1200px;
		position:relative;
		font-family: Arial;
	}
	.bold{font-weight: bold;}
	.italic{font-style: italic;}
	.sz25{font-size:2.5em;}
	.sz20{font-size:1.5em;}
	.sz15{font-size:1.5em;}
	.sz13{font-size:1.3em;}
	.sz12{font-size:1.2em;}
	.sz10{font-size:1.0em;}
	.sz08{font-size:0.8em;}
	.inline{display:inline-block;}
	.no_margin{
		margin: 0 0;
	}
	.padding20{
		padding: 0px;
	}
	/*.halign{*/
	/*	margin-left: auto;*/
	/*	margin-right: auto;*/
	/*}*/
	.block_2
	{
		width:49%;
		max-width: 512px;
		display: inline-block;
		position: relative;
	}
	.block_5_2
	{
		width:40%;
		max-width: 410px;
		display: inline-block;
		position: relative;
	}
	.block_3
	{
		width:33%;
		max_width: 341px;
		display: inline-block;
		position: relative;
	}
	.block_1
	{
		width:100%;
		display: inline-block;
		/*position: relative;*/
		/*margin: 5px 5px;*/
		text-align: justify;

	}
	.block_N
	{
		display: inline-block;
		position: relative;
	}
	.block_6
	{
		width:16%;
		display: inline-block;
		position: relative;

	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 0px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	.block_6_5
	{
		width:83%;
		display: inline-block;
		position: relative;
	}

	.std{
		border: 0.5px dashed black;
		border-collapse: collapse;
	}
	td {
		padding: 15px;
	}
		.link {
			color: #222222;
		}

	</style>
	<title>
		PDUN
	</title>
	<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-141788472-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-141788472-1');
</script>

</head>
<body data-gr-c-s-loaded="true">
<div class="container">

<div style="margin-top: 20px">
	<div style="float: left; width: 10%; margin-left: 5%"><a href="http://deltalab.iitk.ac.in/"><img src="static/delta.png" alt="Delta Lab"/></a></div>
	<div style="float: left; width: 70%;">
	<div class="block_1">

		<div class="block_1">
			<div align="center">
				<p class="sz20 no_margin"><b></b>Probabilistic framework for solving Visual Dialog</p>
			</div>
			<p align="center">
			</p><p class="no_margin bold" align="center"> <a class="link" href="http://home.iitk.ac.in/~badri/index.html">Badri N. Patro</a><sup></sup>, <a class="link">Anupriy </a><sup></sup>, <a class="link" href="https://www.cse.iitk.ac.in/users/vinaypn/">Vinay P. Namboodiri</a></p>
<!--            <p  class="no_margin" align="center"><a href="http://deltalab.iitk.ac.in/">Delta Lab</a></p>-->
<!--				<p class="no_margin" align="center"><a href="http://iitk.ac.in/">Indian Institute of Technology Kanpur</a></p>-->
				<p class="sz12" align="center"><a class="link" href="http://arxiv.org/abs/1909.04800">[ArXiv]</a></a> <a>
			<p align="center">
			</p>
		</div>
	</div>
</div>
	<div style="float: left; width: 10%;"><a href="https://www.iitk.ac.in/"><img src="static/iitk.png"  alt="sherlock"/></a></div>
<!--<div class="halign">
		<div class="block_1">
			<div class="">

			</div>
	</div>
</div>-->

	<div class="block_1">
		<div class="">
			<br>
			<hr>
			<p class="sz15 bold">Abstract:</p>
			<div class="thumbnail" style="float:right; margin-left: 20px" >
					<img src="static/intro.png" alt="l0" style="max-width:400px">
					<div class="caption" style="max-width:400px">
						<p>Proposed Probabilistic Diversity and Uncertainty Network (PDUN) consists of three parts, viz. a) Probabilistic
						Representation Module encodes image feature with a question and history feature in an attentive manner. b) Diversity
						module captures the diversity, and diverse answer is generated using Variational Auto-Encoder. c) Uncertainty module
						predicts uncertainty of the network.</p>
					</div>
			</div>
				<p class="sz12">
					In this paper, we propose a probabilistic framework for solving the task of `Visual Dialog'. Solving this task requires
					reasoning and understanding of visual modality, language modality, and common sense knowledge to answer. Various
					architectures have been proposed to solve this task by variants of multi-modal deep learning techniques that combine
					visual and language representations. However, we believe that it is crucial to understand and analyze the sources of
					uncertainty for solving this task. Our approach allows for estimating uncertainty and also aids a diverse generation of
					answers. The proposed approach is obtained through a probabilistic representation module that provides us with
					representations for image, question and conversation history, a module that ensures that diverse latent representations
					for candidate answers are obtained given the probabilistic representations and an uncertainty representation module that
					chooses the appropriate answer that minimizes uncertainty. We thoroughly evaluate the model with a detailed ablation
					analysis, comparison with state of the art and visualization of the uncertainty that aids in the understanding of the
					method. Using the proposed probabilistic framework, we thus obtain an improved visual dialog system that is also more
					explainable.</p>
		</div>
	</div>

	<div class="thumbnail" style="text-align: center" >
		<img src="static/motivation.png" alt="l2">
		<hr>
		<div class="caption" style="text-align: left !important;">
			<p>
			Results were showing the certainty of the correct class increases from baseline model [9] to our proposed
			uncertainty model (PDUN). In this figure, we show the top 2 class confidence score of the question, "Is this a park?".
			In the baseline model focus on woman, guitar and chair and predicts "NO," which is confused with the correct prediction
			of the answer, whether it is a park or not. PDUN model minimizes the uncertainty and predicts the correct answer "Yes"
			with a high confidence score.
			</p>
		</div>
	</div>


	<p class="sz15 bold">
		<br>
		PDUN Model:
	</p>
	<div class="thumbnail" style="float:right; margin-left: 20px" >
		<img src="static/model_PDUN.png" alt="l3">
		<hr>
		<div class="caption">
			<p>Probabilistic Diversity Uncertainty Network(PDUN), Bayesian CNN/LSTM is used to obtain the embeddings $g_i,f_i,h_i$
			which is then fused using the Fusion Module to get $e_f$. Then correlation is found between fused embedding with answer
			option embedding. Finally, variance and logits output are obtained using MLP, which is then used in Logits
			Reparameterization Trick(LRT) to get final softmax output.</p>
		</div>
	</div>

<p class="sz15 bold">
	<br>
	RUAM Model:
</p>
<div class="thumbnail" style="float:right; margin-left: 20px">
	<img src="static/RUAM.png" alt="l4">
	<hr>
	<div class="caption">
		<p>Reverse Uncertainty based Attention Map (RUAM): We obtain attention embedding $f_i$ from the attention network $G_f$
		using image, question and history embeddings $g_i,g_q,g_h$. Then we classify into answer class and obtain the
		uncertainty present in the data. Then we obtain reverse uncertainty map with will combine with attention map to get
		better confidence on the attention map as shown in the figure.</p>
	</div>
</div>



	<p class="sz15 bold">
		Some example of visual dialog using our method:
	</p>


	<p class="sz15 bold">	
			<br>
			Results:	</p>
	<div class="thumbnail" style="float:right; margin-left: 20px">
		<img src="static/result.png" alt="l5">
		<hr>
		<div class="caption">
			<p>Figure shows the difference between aleatoric dialog results and baseline dialog results. In this figure, the first row
			refers to Grad-CAM visualization of first example for baseline visual dialog model and second row refers to Grad-CAM
			visualization of first example for Aleatoric visual dialog model and same scheme is followed for next 2 rows. The first
			column indicates target Image and corresponding caption and starting from second column is the visualization of rounds
			of dialog from round 1 to 10.</p>
		</div>
	</div>




	<p class="sz15 bold">
	</p>
	<div class="thumbnail" style="float:right; margin-left: 20px">
		<img src="static/result_1.png" alt="l6">
		<hr>
		<!-- <div class="caption">
			<p>Reverse Uncertainty based Attention Map (RUAM): We obtain attention embedding $f_i$ from the attention network
				$G_f$
				using image, question and history embeddings $g_i,g_q,g_h$. Then we classify into answer class and obtain the
				uncertainty present in the data. Then we obtain reverse uncertainty map with will combine with attention map to
				get
				better confidence on the attention map as shown in the figure.</p>
		</div> -->
	</div>

		<p class="sz15 bold">
				<br>
				MC-Sampling for a particular turn of a particular example:
		</p>
		<div class="thumbnail" style="float:right; margin-left: 20px">
			<img src="static/mc_question.png" alt="l7">
			<hr>
			<div class="caption">
				<p>We visualize the multiple outputs from the Bayesian neural network. We took 100 sample from the posterior distribution
				of dialog model for particular image, particular question. It shows how Grad-CAM is flowing for particular image,
				particular question.</p>
			</div>
		</div>

		<p class="sz15 bold">
		<br>
		MC-Sampling for a particular turn of a particular example:
		</p>
		<div class="thumbnail" style="text-align:center">
			<img src="static/aleatoric_uncertainty_ques_gradcam_100.gif" style="max-width:200px">
			<hr>
		</div>

<!-- 	
<p class="sz15 bold">
	Cite us
</p>

 
<div class="well" style="font-family: monospace">
@inproceedings{Patro_ICCV2019,
	<br>
  title={U-CAM: Visual Explanation using Uncertainty based Class Activation Maps},
	<br>
  author={Badri N. Patro and Mayank Lunayach and Shivansh Patel and Vinay P. Namboodiri},
	<br>
  booktitle={arXiv preprint arXiv:1908.06306},
<br>
  year={2019}}
</div>

-->

</div>
</div>
<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-141358857-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-141358857-1');
</script>


<script type="text/javascript">

</script>

</body></html>
